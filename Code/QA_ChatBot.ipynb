{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_ChatBot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1T8bgQ-KS3Rg9mqwmkFNG9D58AnSoDQ1R",
      "authorship_tag": "ABX9TyPNWCwnBRq6BRzOvCa2cdMP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ztUsOZtxC4",
        "colab_type": "text"
      },
      "source": [
        "# Question Answer ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsrjrM5t78j",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1QksIAts3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnp_rB1duGwb",
        "colab_type": "text"
      },
      "source": [
        "## 2) Reading data from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYlwo1eruFkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For training\n",
        "\n",
        "with open('drive/My Drive/Pytorch_DataSet/TextFiles/train_qa.txt','rb') as f:\n",
        "  train_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7uqXwzub5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For testing\n",
        "\n",
        "with open('drive/My Drive/Pytorch_DataSet/TextFiles/test_qa.txt','rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWH8ujECukc-",
        "colab_type": "code",
        "outputId": "32e768f4-74ef-48a8-e096-193292681250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-TNws4TunrS",
        "colab_type": "code",
        "outputId": "21bf0013-facb-4b1e-9ec3-510cf6f6c3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yARv8Fnvu3e4",
        "colab_type": "code",
        "outputId": "9f4bbad8-47ec-4255-a051-8327f8123941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tVMHKKvDaB",
        "colab_type": "code",
        "outputId": "5e89e223-fd94-457b-f54a-e79f54a3c4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1WkErkpvQq7",
        "colab_type": "code",
        "outputId": "fd63bfce-e93b-444b-9359-53a8457f1653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join(train_data[0][2])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmnTrFlgvT_c",
        "colab_type": "code",
        "outputId": "e5343ac0-90a6-42d4-9b84-48f8109d0560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data), type(test_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRLLcWE6wK0Y",
        "colab_type": "text"
      },
      "source": [
        "## 3) Creating a dictionary.\n",
        "\n",
        "Creating a dictionary that contains all the words our train and test set has got so that the test data do not contain any word which is not present in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fNwT-RzvgKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dolfQs4wwjx6",
        "colab_type": "code",
        "outputId": "d273aad6-b4fd-4836-a225-a64e99348a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H294U9O5wz6v",
        "colab_type": "code",
        "outputId": "1d41cbee-4ecc-4590-c235-a927058e42d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_data[0][0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8esvDZYxgSu",
        "colab_type": "code",
        "outputId": "63bd44c6-4a22-4c3e-d34a-3f28f92e751e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "set(train_data[0][0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'journeyed',\n",
              " 'moved',\n",
              " 'the',\n",
              " 'to'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqBF5UTBxi47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for statement,query, answer in all_data:\n",
        "  vocab = vocab.union(set(statement))\n",
        "  vocab = vocab.union(set(query))\n",
        "\n",
        "vocab.add('no')\n",
        "vocab.add('yes')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucVP9iQyBi0",
        "colab_type": "code",
        "outputId": "3bed17f3-28ac-485b-f7fc-bf5488b432d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f8dLk9VyC2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the pad sequences in case if the string is too short or too long\n",
        "vocab_len = len(vocab) + 1 # 1 for padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vUGGGYhyg-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, checking the length of the longest story that can be used in padding\n",
        "\n",
        "#Longest story\n",
        "\n",
        "all_story_len = [len(data[0]) for data in all_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZItciCw4zOcA",
        "colab_type": "code",
        "outputId": "96537621-3e93-4c05-a91a-671e5336b70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_story_len[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 26, 39, 52, 64, 12, 24, 36, 49, 61]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIEkIiOXzPgV",
        "colab_type": "code",
        "outputId": "79bca90c-5c5a-4ea8-f3de-67c9167490de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_story_len = max(all_story_len)\n",
        "max_story_len"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPXKbWjfzYQK",
        "colab_type": "code",
        "outputId": "2eeb7155-13b7-4c50-8dbb-b28b932b027a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_question_len = [len(data[1]) for data in all_data]\n",
        "all_question_len[:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdHIVIGYFeDU",
        "colab_type": "code",
        "outputId": "81dd2ebe-01f7-4b6e-ea77-222b066ec83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_question_len = max(all_question_len)\n",
        "max_question_len"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGKhXnKfitXn",
        "colab_type": "text"
      },
      "source": [
        "## 4) Vectorizing the Data\n",
        "\n",
        "Conversion of text into numerical values\n",
        "\n",
        "https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDUNkVyFqAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_il-qPHfjD3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBDB72LdjoQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "446b0a23-34a1-4afd-bc55-95dfe70d3c0c"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 31,\n",
              " '?': 16,\n",
              " 'apple': 37,\n",
              " 'back': 5,\n",
              " 'bathroom': 11,\n",
              " 'bedroom': 21,\n",
              " 'daniel': 27,\n",
              " 'discarded': 8,\n",
              " 'down': 35,\n",
              " 'dropped': 13,\n",
              " 'football': 33,\n",
              " 'garden': 18,\n",
              " 'got': 6,\n",
              " 'grabbed': 30,\n",
              " 'hallway': 17,\n",
              " 'in': 26,\n",
              " 'is': 22,\n",
              " 'john': 9,\n",
              " 'journeyed': 29,\n",
              " 'kitchen': 32,\n",
              " 'left': 25,\n",
              " 'mary': 36,\n",
              " 'milk': 3,\n",
              " 'moved': 1,\n",
              " 'no': 23,\n",
              " 'office': 24,\n",
              " 'picked': 15,\n",
              " 'put': 7,\n",
              " 'sandra': 12,\n",
              " 'the': 14,\n",
              " 'there': 34,\n",
              " 'to': 10,\n",
              " 'took': 4,\n",
              " 'travelled': 19,\n",
              " 'up': 28,\n",
              " 'went': 2,\n",
              " 'yes': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ckqMeojvKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separating the story, question and answer from the training set\n",
        "\n",
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answer_text = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_question_text.append(question)\n",
        "  train_answer_text.append(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEwzz-elrQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "43b1cccf-fa0d-4bee-8d93-d0b867c74ddd"
      },
      "source": [
        "train_story_text[:1]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sLmQokls_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the story , question and answer in numerical form\n",
        "\n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G_xGpMPnG0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32d1095-bde1-48d2-89ca-f8138f9ac5c3"
      },
      "source": [
        "train_story_seq[:1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 1, 10, 14, 11, 31, 12, 29, 10, 14, 21, 31]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0aM8MQinIjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        " \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "  \n",
        "  \n",
        "  for story, query, answer in data:\n",
        "      \n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "    # Index 0 is reserved so we're going to use + 1\n",
        "    y = np.zeros(len(word_index) + 1)\n",
        "    \n",
        "    \n",
        "    y[word_index[answer]] = 1\n",
        "    \n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "      \n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "      \n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ORx454yH58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Qbq2hSyLEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcke-ta2yNjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "398fed43-783d-4e18-c724-0094bde0c955"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ..., 14, 17, 31],\n",
              "       [ 0,  0,  0, ..., 14, 11, 31],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ...,  3, 34, 31],\n",
              "       [ 0,  0,  0, ..., 37, 34, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMc_KeZcyWEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "84502ff1-3d2b-40b5-a455-96ad46fe3df3"
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 14, 37, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       [ 0,  0,  0, ..., 37, 34, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou85hftJyZTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9e197518-a8a5-425a-98ee-8ac3fd898e4c"
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvdg3AGzK5zu",
        "colab_type": "text"
      },
      "source": [
        "## 5) Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1RM4RWRycqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAsGotd4K_tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have two inputs, stories and questions. So we need to use placeholders. Input() is used to instantiate a Keras tensor.\n",
        "# PlaceHolder shape = (max_story_len,batch_size)\n",
        "\n",
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))\n",
        "\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTOViNpOmiC",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnHQXaXMDBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeJAU9LDOq8T",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaGsssBROQHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U5o1QlwOzZe",
        "colab_type": "text"
      },
      "source": [
        "Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-zF4Y1OcTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzYWX-pRHlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "\n",
        "# ENCODED <---- ENCODER (INPUT)\n",
        "\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRbw6Z8qRJYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxadf04bS3xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPmWuGhS6iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfzstpYBS9Vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e0d6395-3876-43fb-9fb1-603c8b43cdd4"
      },
      "source": [
        "answer"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjdm2ZlaTQht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsADqRvFTUx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seq0720uTYLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLZFRWDTpu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "4275baa6-c8d6-49ca-e82d-a8ab9aa035b7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             2432        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[2][0]               \n",
            "                                                                 sequential_4[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       multiple             228         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_3[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_4[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8tZzpKIXBkh",
        "colab_type": "text"
      },
      "source": [
        "## 6) Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9ZgrHLNTvwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca410771-6445-45a8-e0ce-7c2fa549b8de"
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/120\n",
            "10000/10000 [==============================] - 5s 519us/step - loss: 0.8716 - accuracy: 0.5003 - val_loss: 0.7011 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.6994 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 3/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.6960 - accuracy: 0.4930 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.6946 - accuracy: 0.5048 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.6947 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.6945 - accuracy: 0.4967 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
            "Epoch 7/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.6947 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
            "Epoch 8/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.6947 - accuracy: 0.4969 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
            "Epoch 9/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.6944 - accuracy: 0.4961 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.6943 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 11/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.6944 - accuracy: 0.4998 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 12/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.6942 - accuracy: 0.4939 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
            "Epoch 13/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.6940 - accuracy: 0.5027 - val_loss: 0.6934 - val_accuracy: 0.5070\n",
            "Epoch 14/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6853 - val_accuracy: 0.5500\n",
            "Epoch 15/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.6292 - accuracy: 0.6508 - val_loss: 0.5332 - val_accuracy: 0.7670\n",
            "Epoch 16/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.4904 - accuracy: 0.7859 - val_loss: 0.4405 - val_accuracy: 0.8230\n",
            "Epoch 17/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.4359 - accuracy: 0.8212 - val_loss: 0.4104 - val_accuracy: 0.8260\n",
            "Epoch 18/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.4000 - accuracy: 0.8347 - val_loss: 0.4041 - val_accuracy: 0.8340\n",
            "Epoch 19/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3857 - accuracy: 0.8424 - val_loss: 0.3976 - val_accuracy: 0.8360\n",
            "Epoch 20/120\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.3717 - accuracy: 0.8473 - val_loss: 0.3899 - val_accuracy: 0.8410\n",
            "Epoch 21/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.3598 - accuracy: 0.8563 - val_loss: 0.3809 - val_accuracy: 0.8350\n",
            "Epoch 22/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3553 - accuracy: 0.8542 - val_loss: 0.3805 - val_accuracy: 0.8410\n",
            "Epoch 23/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3498 - accuracy: 0.8554 - val_loss: 0.3691 - val_accuracy: 0.8360\n",
            "Epoch 24/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.3433 - accuracy: 0.8571 - val_loss: 0.3625 - val_accuracy: 0.8390\n",
            "Epoch 25/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.3324 - accuracy: 0.8625 - val_loss: 0.3533 - val_accuracy: 0.8420\n",
            "Epoch 26/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.3248 - accuracy: 0.8601 - val_loss: 0.3546 - val_accuracy: 0.8460\n",
            "Epoch 27/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3216 - accuracy: 0.8655 - val_loss: 0.3422 - val_accuracy: 0.8450\n",
            "Epoch 28/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3141 - accuracy: 0.8633 - val_loss: 0.3479 - val_accuracy: 0.8310\n",
            "Epoch 29/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3134 - accuracy: 0.8616 - val_loss: 0.3436 - val_accuracy: 0.8450\n",
            "Epoch 30/120\n",
            "10000/10000 [==============================] - 4s 443us/step - loss: 0.3094 - accuracy: 0.8681 - val_loss: 0.3500 - val_accuracy: 0.8440\n",
            "Epoch 31/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.3065 - accuracy: 0.8658 - val_loss: 0.3413 - val_accuracy: 0.8440\n",
            "Epoch 32/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.3068 - accuracy: 0.8645 - val_loss: 0.3396 - val_accuracy: 0.8440\n",
            "Epoch 33/120\n",
            "10000/10000 [==============================] - 4s 446us/step - loss: 0.3051 - accuracy: 0.8664 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 34/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.3028 - accuracy: 0.8676 - val_loss: 0.3471 - val_accuracy: 0.8340\n",
            "Epoch 35/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.3025 - accuracy: 0.8699 - val_loss: 0.3493 - val_accuracy: 0.8410\n",
            "Epoch 36/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2998 - accuracy: 0.8692 - val_loss: 0.3494 - val_accuracy: 0.8450\n",
            "Epoch 37/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2980 - accuracy: 0.8697 - val_loss: 0.3738 - val_accuracy: 0.8240\n",
            "Epoch 38/120\n",
            "10000/10000 [==============================] - 4s 444us/step - loss: 0.2994 - accuracy: 0.8706 - val_loss: 0.3474 - val_accuracy: 0.8470\n",
            "Epoch 39/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2950 - accuracy: 0.8693 - val_loss: 0.3455 - val_accuracy: 0.8460\n",
            "Epoch 40/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2916 - accuracy: 0.8727 - val_loss: 0.3674 - val_accuracy: 0.8390\n",
            "Epoch 41/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2942 - accuracy: 0.8698 - val_loss: 0.3480 - val_accuracy: 0.8400\n",
            "Epoch 42/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2926 - accuracy: 0.8710 - val_loss: 0.3473 - val_accuracy: 0.8450\n",
            "Epoch 43/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2919 - accuracy: 0.8729 - val_loss: 0.3581 - val_accuracy: 0.8470\n",
            "Epoch 44/120\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.2891 - accuracy: 0.8706 - val_loss: 0.3631 - val_accuracy: 0.8390\n",
            "Epoch 45/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2872 - accuracy: 0.8744 - val_loss: 0.3595 - val_accuracy: 0.8400\n",
            "Epoch 46/120\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.2884 - accuracy: 0.8760 - val_loss: 0.3646 - val_accuracy: 0.8410\n",
            "Epoch 47/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2837 - accuracy: 0.8721 - val_loss: 0.3585 - val_accuracy: 0.8440\n",
            "Epoch 48/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2843 - accuracy: 0.8738 - val_loss: 0.3662 - val_accuracy: 0.8470\n",
            "Epoch 49/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2830 - accuracy: 0.8738 - val_loss: 0.3498 - val_accuracy: 0.8420\n",
            "Epoch 50/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2831 - accuracy: 0.8759 - val_loss: 0.3501 - val_accuracy: 0.8450\n",
            "Epoch 51/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2811 - accuracy: 0.8749 - val_loss: 0.3553 - val_accuracy: 0.8430\n",
            "Epoch 52/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2793 - accuracy: 0.8772 - val_loss: 0.3911 - val_accuracy: 0.8360\n",
            "Epoch 53/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2813 - accuracy: 0.8753 - val_loss: 0.3562 - val_accuracy: 0.8410\n",
            "Epoch 54/120\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.2812 - accuracy: 0.8774 - val_loss: 0.3479 - val_accuracy: 0.8390\n",
            "Epoch 55/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2811 - accuracy: 0.8752 - val_loss: 0.3674 - val_accuracy: 0.8450\n",
            "Epoch 56/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2777 - accuracy: 0.8744 - val_loss: 0.3750 - val_accuracy: 0.8410\n",
            "Epoch 57/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2753 - accuracy: 0.8773 - val_loss: 0.3674 - val_accuracy: 0.8400\n",
            "Epoch 58/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2765 - accuracy: 0.8781 - val_loss: 0.3584 - val_accuracy: 0.8400\n",
            "Epoch 59/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2787 - accuracy: 0.8779 - val_loss: 0.3622 - val_accuracy: 0.8440\n",
            "Epoch 60/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2753 - accuracy: 0.8795 - val_loss: 0.3880 - val_accuracy: 0.8370\n",
            "Epoch 61/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2734 - accuracy: 0.8797 - val_loss: 0.3888 - val_accuracy: 0.8390\n",
            "Epoch 62/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2719 - accuracy: 0.8811 - val_loss: 0.3835 - val_accuracy: 0.8360\n",
            "Epoch 63/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2756 - accuracy: 0.8807 - val_loss: 0.3784 - val_accuracy: 0.8400\n",
            "Epoch 64/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2734 - accuracy: 0.8826 - val_loss: 0.3725 - val_accuracy: 0.8420\n",
            "Epoch 65/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2679 - accuracy: 0.8824 - val_loss: 0.4007 - val_accuracy: 0.8370\n",
            "Epoch 66/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2745 - accuracy: 0.8787 - val_loss: 0.4023 - val_accuracy: 0.8440\n",
            "Epoch 67/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2674 - accuracy: 0.8790 - val_loss: 0.3685 - val_accuracy: 0.8410\n",
            "Epoch 68/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2673 - accuracy: 0.8850 - val_loss: 0.3719 - val_accuracy: 0.8420\n",
            "Epoch 69/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2700 - accuracy: 0.8813 - val_loss: 0.3924 - val_accuracy: 0.8420\n",
            "Epoch 70/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2672 - accuracy: 0.8801 - val_loss: 0.3738 - val_accuracy: 0.8370\n",
            "Epoch 71/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2632 - accuracy: 0.8834 - val_loss: 0.4178 - val_accuracy: 0.8350\n",
            "Epoch 72/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2636 - accuracy: 0.8860 - val_loss: 0.3882 - val_accuracy: 0.8410\n",
            "Epoch 73/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2595 - accuracy: 0.8843 - val_loss: 0.3677 - val_accuracy: 0.8430\n",
            "Epoch 74/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2610 - accuracy: 0.8871 - val_loss: 0.3794 - val_accuracy: 0.8400\n",
            "Epoch 75/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2586 - accuracy: 0.8879 - val_loss: 0.3883 - val_accuracy: 0.8320\n",
            "Epoch 76/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2598 - accuracy: 0.8857 - val_loss: 0.3771 - val_accuracy: 0.8400\n",
            "Epoch 77/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2638 - accuracy: 0.8846 - val_loss: 0.3998 - val_accuracy: 0.8450\n",
            "Epoch 78/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2576 - accuracy: 0.8885 - val_loss: 0.3958 - val_accuracy: 0.8360\n",
            "Epoch 79/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2608 - accuracy: 0.8878 - val_loss: 0.3811 - val_accuracy: 0.8370\n",
            "Epoch 80/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2572 - accuracy: 0.8863 - val_loss: 0.4239 - val_accuracy: 0.8350\n",
            "Epoch 81/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2559 - accuracy: 0.8861 - val_loss: 0.4165 - val_accuracy: 0.8400\n",
            "Epoch 82/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2538 - accuracy: 0.8873 - val_loss: 0.4153 - val_accuracy: 0.8400\n",
            "Epoch 83/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2521 - accuracy: 0.8910 - val_loss: 0.4354 - val_accuracy: 0.8290\n",
            "Epoch 84/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2554 - accuracy: 0.8869 - val_loss: 0.4104 - val_accuracy: 0.8410\n",
            "Epoch 85/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2523 - accuracy: 0.8901 - val_loss: 0.3852 - val_accuracy: 0.8450\n",
            "Epoch 86/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2508 - accuracy: 0.8921 - val_loss: 0.4183 - val_accuracy: 0.8340\n",
            "Epoch 87/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2510 - accuracy: 0.8915 - val_loss: 0.3928 - val_accuracy: 0.8360\n",
            "Epoch 88/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2479 - accuracy: 0.8929 - val_loss: 0.4273 - val_accuracy: 0.8350\n",
            "Epoch 89/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2496 - accuracy: 0.8934 - val_loss: 0.4196 - val_accuracy: 0.8450\n",
            "Epoch 90/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2462 - accuracy: 0.8917 - val_loss: 0.4347 - val_accuracy: 0.8400\n",
            "Epoch 91/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2461 - accuracy: 0.8956 - val_loss: 0.3941 - val_accuracy: 0.8380\n",
            "Epoch 92/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2475 - accuracy: 0.8946 - val_loss: 0.4313 - val_accuracy: 0.8350\n",
            "Epoch 93/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2433 - accuracy: 0.8946 - val_loss: 0.4254 - val_accuracy: 0.8410\n",
            "Epoch 94/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2406 - accuracy: 0.8966 - val_loss: 0.4249 - val_accuracy: 0.8380\n",
            "Epoch 95/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2360 - accuracy: 0.8988 - val_loss: 0.4616 - val_accuracy: 0.8410\n",
            "Epoch 96/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2408 - accuracy: 0.8964 - val_loss: 0.4198 - val_accuracy: 0.8440\n",
            "Epoch 97/120\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.2411 - accuracy: 0.8973 - val_loss: 0.4337 - val_accuracy: 0.8400\n",
            "Epoch 98/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2398 - accuracy: 0.8980 - val_loss: 0.4292 - val_accuracy: 0.8370\n",
            "Epoch 99/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2370 - accuracy: 0.8976 - val_loss: 0.4430 - val_accuracy: 0.8390\n",
            "Epoch 100/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2321 - accuracy: 0.9004 - val_loss: 0.4546 - val_accuracy: 0.8360\n",
            "Epoch 101/120\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.2337 - accuracy: 0.9020 - val_loss: 0.4719 - val_accuracy: 0.8320\n",
            "Epoch 102/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2375 - accuracy: 0.9014 - val_loss: 0.4503 - val_accuracy: 0.8390\n",
            "Epoch 103/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2333 - accuracy: 0.9002 - val_loss: 0.4435 - val_accuracy: 0.8410\n",
            "Epoch 104/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2307 - accuracy: 0.9030 - val_loss: 0.4360 - val_accuracy: 0.8390\n",
            "Epoch 105/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2299 - accuracy: 0.9029 - val_loss: 0.4501 - val_accuracy: 0.8400\n",
            "Epoch 106/120\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 0.2305 - accuracy: 0.9033 - val_loss: 0.4717 - val_accuracy: 0.8360\n",
            "Epoch 107/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2308 - accuracy: 0.8986 - val_loss: 0.4805 - val_accuracy: 0.8350\n",
            "Epoch 108/120\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.2263 - accuracy: 0.9038 - val_loss: 0.5267 - val_accuracy: 0.8360\n",
            "Epoch 109/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2259 - accuracy: 0.9073 - val_loss: 0.4911 - val_accuracy: 0.8290\n",
            "Epoch 110/120\n",
            "10000/10000 [==============================] - 4s 450us/step - loss: 0.2343 - accuracy: 0.9050 - val_loss: 0.4793 - val_accuracy: 0.8410\n",
            "Epoch 111/120\n",
            "10000/10000 [==============================] - 4s 444us/step - loss: 0.2263 - accuracy: 0.9077 - val_loss: 0.4988 - val_accuracy: 0.8470\n",
            "Epoch 112/120\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.2201 - accuracy: 0.9040 - val_loss: 0.4600 - val_accuracy: 0.8460\n",
            "Epoch 113/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2224 - accuracy: 0.9051 - val_loss: 0.5027 - val_accuracy: 0.8350\n",
            "Epoch 114/120\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.2207 - accuracy: 0.9070 - val_loss: 0.4634 - val_accuracy: 0.8400\n",
            "Epoch 115/120\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2211 - accuracy: 0.9102 - val_loss: 0.5178 - val_accuracy: 0.8470\n",
            "Epoch 116/120\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.2204 - accuracy: 0.9128 - val_loss: 0.4609 - val_accuracy: 0.8360\n",
            "Epoch 117/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2226 - accuracy: 0.9035 - val_loss: 0.4691 - val_accuracy: 0.8430\n",
            "Epoch 118/120\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2170 - accuracy: 0.9081 - val_loss: 0.5405 - val_accuracy: 0.8470\n",
            "Epoch 119/120\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2196 - accuracy: 0.9097 - val_loss: 0.4865 - val_accuracy: 0.8380\n",
            "Epoch 120/120\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.2171 - accuracy: 0.9104 - val_loss: 0.4902 - val_accuracy: 0.8400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1COdF1W_Wi",
        "colab_type": "text"
      },
      "source": [
        "## 7) Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOIWFdhUuAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = 'chatbot.h5'\n",
        "model.save(modelname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRdSBciCXY7B",
        "colab_type": "text"
      },
      "source": [
        "## 8) Plotting the graph of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQJqqK0GXQx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "02185620-e419-41c6-cdcb-64e1e883ebf6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkNoTYt_X9oK",
        "colab_type": "text"
      },
      "source": [
        "## 9) Prediction on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOz-aXe1XiTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(modelname)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVUHZZIcYMeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "da3df1c7-5ba1-4a53-f89c-7a4bafb406fd"
      },
      "source": [
        "test_data[0][0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-e_pa-AYP1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e0c785-0c8a-4282-b88c-f344260e3aa4"
      },
      "source": [
        "test_data[0][1]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'John', 'in', 'the', 'kitchen', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpfWL2FpYYyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c069ca26-fac6-4021-f0df-256d03f19cc8"
      },
      "source": [
        "test_data[0][2]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-xR1jY-YpVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ed6e6f9c-55cc-445e-cb33-e85a37665d76"
      },
      "source": [
        "pred_results[0]   # Probability of occurence of each word from vocab in the answer."
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.2007923e-19, 6.9919850e-19, 7.4148165e-19, 5.5341123e-19,\n",
              "       4.9508021e-19, 5.5920894e-19, 5.8494475e-19, 7.5741382e-19,\n",
              "       6.4324051e-19, 8.2057015e-19, 6.3539015e-19, 5.8938640e-19,\n",
              "       5.7842776e-19, 5.1010253e-19, 6.9749886e-19, 5.9041252e-19,\n",
              "       6.2742492e-19, 4.5140032e-19, 7.4606671e-19, 6.5306850e-19,\n",
              "       6.1788984e-07, 5.2651783e-19, 6.3753152e-19, 9.9999940e-01,\n",
              "       6.3035169e-19, 6.1542791e-19, 7.1467723e-19, 6.0915426e-19,\n",
              "       5.2559873e-19, 5.4226445e-19, 7.5737629e-19, 6.2120664e-19,\n",
              "       4.9811307e-19, 4.8479195e-19, 7.2329753e-19, 6.4288731e-19,\n",
              "       5.4878419e-19, 6.8437077e-19], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj_whrg2YjoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "087c2bf6-1525-4983-d888-6888b59e3d0e"
      },
      "source": [
        "# Generating prediction from model\n",
        "\n",
        "val_max = np.argmax(pred_results[0])\n",
        "val_max"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro5MXlYBYbPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a3ed6d91-2971-4a86-802c-225dbe6f385c"
      },
      "source": [
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6wZcZhGa6cL",
        "colab_type": "text"
      },
      "source": [
        "## 10) Making our own story\n",
        "\n",
        "we can only use words from our current vocabulary as our model only know these words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEnRGNbjZJ4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "36339341-a227-460e-bb71-cfc12f76f9e4"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwPrLm82bOFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8cd3d3c7-a41f-43ff-b84b-8b5885e5a89a"
      },
      "source": [
        "# Put whitespace of the periods as we want our story and question format to be in same order as that of training and test set\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6xqrBZDbeOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17785d14-d6ae-4b02-fe52-b03f164d142b"
      },
      "source": [
        "my_question = \"Is the football in the garden ?\"\n",
        "my_question.split()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF8Ho10kbkfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFNwdbbQbscO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5d81c55a-3e2b-4542-91e5-cbeaaff953a5"
      },
      "source": [
        "my_story"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,\n",
              "        25, 14, 32, 31, 12, 13, 14, 33, 26, 14, 18, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLyEn6snbuIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "409700a2-2e89-4bd9-b961-7157ebfaf3a5"
      },
      "source": [
        "my_ques"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14, 33, 26, 14, 18, 16]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV9e60JdbvcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "75cff3f9-d615-4211-9ad1-6340eb56d487"
      },
      "source": [
        "my_ans"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LOIMDDQbwYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqbZe3khb05F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e31ba99e-951e-4447-c22d-32a1ae7884b4"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9998535\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}