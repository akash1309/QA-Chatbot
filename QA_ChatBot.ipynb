{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_ChatBot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1T8bgQ-KS3Rg9mqwmkFNG9D58AnSoDQ1R",
      "authorship_tag": "ABX9TyOxzyxGQF6DjLpHeaqafp4w"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ztUsOZtxC4",
        "colab_type": "text"
      },
      "source": [
        "# Question Answer ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsrjrM5t78j",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1QksIAts3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnp_rB1duGwb",
        "colab_type": "text"
      },
      "source": [
        "## 2) Reading data from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYlwo1eruFkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For training\n",
        "\n",
        "with open('drive/My Drive/Pytorch_DataSet/TextFiles/train_qa.txt','rb') as f:\n",
        "  train_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7uqXwzub5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For testing\n",
        "\n",
        "with open('drive/My Drive/Pytorch_DataSet/TextFiles/test_qa.txt','rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWH8ujECukc-",
        "colab_type": "code",
        "outputId": "32e768f4-74ef-48a8-e096-193292681250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-TNws4TunrS",
        "colab_type": "code",
        "outputId": "21bf0013-facb-4b1e-9ec3-510cf6f6c3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yARv8Fnvu3e4",
        "colab_type": "code",
        "outputId": "9f4bbad8-47ec-4255-a051-8327f8123941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tVMHKKvDaB",
        "colab_type": "code",
        "outputId": "5e89e223-fd94-457b-f54a-e79f54a3c4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1WkErkpvQq7",
        "colab_type": "code",
        "outputId": "fd63bfce-e93b-444b-9359-53a8457f1653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join(train_data[0][2])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmnTrFlgvT_c",
        "colab_type": "code",
        "outputId": "e5343ac0-90a6-42d4-9b84-48f8109d0560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data), type(test_data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRLLcWE6wK0Y",
        "colab_type": "text"
      },
      "source": [
        "## 3) Creating a dictionary.\n",
        "\n",
        "Creating a dictionary that contains all the words our train and test set has got so that the test data do not contain any word which is not present in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fNwT-RzvgKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dolfQs4wwjx6",
        "colab_type": "code",
        "outputId": "d273aad6-b4fd-4836-a225-a64e99348a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H294U9O5wz6v",
        "colab_type": "code",
        "outputId": "1d41cbee-4ecc-4590-c235-a927058e42d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_data[0][0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8esvDZYxgSu",
        "colab_type": "code",
        "outputId": "63bd44c6-4a22-4c3e-d34a-3f28f92e751e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "set(train_data[0][0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'journeyed',\n",
              " 'moved',\n",
              " 'the',\n",
              " 'to'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqBF5UTBxi47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for statement,query, answer in all_data:\n",
        "  vocab = vocab.union(set(statement))\n",
        "  vocab = vocab.union(set(query))\n",
        "\n",
        "vocab.add('no')\n",
        "vocab.add('yes')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucVP9iQyBi0",
        "colab_type": "code",
        "outputId": "3bed17f3-28ac-485b-f7fc-bf5488b432d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f8dLk9VyC2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the pad sequences in case if the string is too short or too long\n",
        "vocab_len = len(vocab) + 1 # 1 for padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vUGGGYhyg-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, checking the length of the longest story that can be used in padding\n",
        "\n",
        "#Longest story\n",
        "\n",
        "all_story_len = [len(data[0]) for data in all_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZItciCw4zOcA",
        "colab_type": "code",
        "outputId": "96537621-3e93-4c05-a91a-671e5336b70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_story_len[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 26, 39, 52, 64, 12, 24, 36, 49, 61]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIEkIiOXzPgV",
        "colab_type": "code",
        "outputId": "79bca90c-5c5a-4ea8-f3de-67c9167490de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_story_len = max(all_story_len)\n",
        "max_story_len"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPXKbWjfzYQK",
        "colab_type": "code",
        "outputId": "2eeb7155-13b7-4c50-8dbb-b28b932b027a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_question_len = [len(data[1]) for data in all_data]\n",
        "all_question_len[:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdHIVIGYFeDU",
        "colab_type": "code",
        "outputId": "81dd2ebe-01f7-4b6e-ea77-222b066ec83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_question_len = max(all_question_len)\n",
        "max_question_len"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGKhXnKfitXn",
        "colab_type": "text"
      },
      "source": [
        "## 4) Vectorizing the Data\n",
        "\n",
        "Conversion of text into numerical values\n",
        "\n",
        "https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDUNkVyFqAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_il-qPHfjD3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBDB72LdjoQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "446b0a23-34a1-4afd-bc55-95dfe70d3c0c"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 31,\n",
              " '?': 16,\n",
              " 'apple': 37,\n",
              " 'back': 5,\n",
              " 'bathroom': 11,\n",
              " 'bedroom': 21,\n",
              " 'daniel': 27,\n",
              " 'discarded': 8,\n",
              " 'down': 35,\n",
              " 'dropped': 13,\n",
              " 'football': 33,\n",
              " 'garden': 18,\n",
              " 'got': 6,\n",
              " 'grabbed': 30,\n",
              " 'hallway': 17,\n",
              " 'in': 26,\n",
              " 'is': 22,\n",
              " 'john': 9,\n",
              " 'journeyed': 29,\n",
              " 'kitchen': 32,\n",
              " 'left': 25,\n",
              " 'mary': 36,\n",
              " 'milk': 3,\n",
              " 'moved': 1,\n",
              " 'no': 23,\n",
              " 'office': 24,\n",
              " 'picked': 15,\n",
              " 'put': 7,\n",
              " 'sandra': 12,\n",
              " 'the': 14,\n",
              " 'there': 34,\n",
              " 'to': 10,\n",
              " 'took': 4,\n",
              " 'travelled': 19,\n",
              " 'up': 28,\n",
              " 'went': 2,\n",
              " 'yes': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ckqMeojvKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separating the story, question and answer from the training set\n",
        "\n",
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answer_text = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_question_text.append(question)\n",
        "  train_answer_text.append(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEwzz-elrQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "43b1cccf-fa0d-4bee-8d93-d0b867c74ddd"
      },
      "source": [
        "train_story_text[:1]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sLmQokls_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the story , question and answer in numerical form\n",
        "\n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G_xGpMPnG0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32d1095-bde1-48d2-89ca-f8138f9ac5c3"
      },
      "source": [
        "train_story_seq[:1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 1, 10, 14, 11, 31, 12, 29, 10, 14, 21, 31]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0aM8MQinIjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        " \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "  \n",
        "  \n",
        "  for story, query, answer in data:\n",
        "      \n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "    # Index 0 is reserved so we're going to use + 1\n",
        "    y = np.zeros(len(word_index) + 1)\n",
        "    \n",
        "    \n",
        "    y[word_index[answer]] = 1\n",
        "    \n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "      \n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "      \n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ORx454yH58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Qbq2hSyLEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcke-ta2yNjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "398fed43-783d-4e18-c724-0094bde0c955"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ..., 14, 17, 31],\n",
              "       [ 0,  0,  0, ..., 14, 11, 31],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ...,  3, 34, 31],\n",
              "       [ 0,  0,  0, ..., 37, 34, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMc_KeZcyWEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "84502ff1-3d2b-40b5-a455-96ad46fe3df3"
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 14, 21, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 14, 37, 31],\n",
              "       [ 0,  0,  0, ..., 14, 18, 31],\n",
              "       [ 0,  0,  0, ..., 37, 34, 31]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou85hftJyZTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9e197518-a8a5-425a-98ee-8ac3fd898e4c"
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvdg3AGzK5zu",
        "colab_type": "text"
      },
      "source": [
        "## 5) Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1RM4RWRycqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAsGotd4K_tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have two inputs, stories and questions. So we need to use placeholders. Input() is used to instantiate a Keras tensor.\n",
        "# PlaceHolder shape = (max_story_len,batch_size)\n",
        "\n",
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))\n",
        "\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTOViNpOmiC",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnHQXaXMDBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeJAU9LDOq8T",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaGsssBROQHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U5o1QlwOzZe",
        "colab_type": "text"
      },
      "source": [
        "Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-zF4Y1OcTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzYWX-pRHlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "\n",
        "# ENCODED <---- ENCODER (INPUT)\n",
        "\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRbw6Z8qRJYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxadf04bS3xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPmWuGhS6iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfzstpYBS9Vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e0d6395-3876-43fb-9fb1-603c8b43cdd4"
      },
      "source": [
        "answer"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjdm2ZlaTQht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsADqRvFTUx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seq0720uTYLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLZFRWDTpu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "4275baa6-c8d6-49ca-e82d-a8ab9aa035b7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             2432        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[2][0]               \n",
            "                                                                 sequential_4[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       multiple             228         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_3[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_4[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9ZgrHLNTvwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}